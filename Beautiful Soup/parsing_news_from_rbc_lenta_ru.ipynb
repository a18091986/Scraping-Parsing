{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "parsing-news-from-rbc-lenta-ru.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[ВЗЯТО ОТСЮДА](https://github.com/hardesttype)"
      ],
      "metadata": {
        "id": "24SB-OMqtHcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Парсер новостных текстов с сайтов РБК и Лента.ру"
      ],
      "metadata": {
        "id": "Kx_mHZLiyNEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек и описание классов"
      ],
      "metadata": {
        "id": "ZDPZoZ8sjRpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка библиотек\n",
        "!pip install bs4\n",
        "!pip install openpyxl"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qwp3j8MjRpS",
        "outputId": "3b2ddf6f-0794-4146-b9ff-c1d34adfd23d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import requests as rq\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from IPython import display"
      ],
      "metadata": {
        "trusted": true,
        "id": "bmtJPEdnjRpT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже описаны классы для извлечения данных. \n",
        "\n",
        "Используются поисковые движки сайтов, возвращающие по запросу json таблицы с информацией о статьях. \n",
        "\n",
        "При их использовании есть различные ограничения, например, на количество статей в запросе. Так на сайте РБК выдается максимум 100 статей, в то время как на Ленте.ру можно получить сразу 1000. По моим наблюдениям, запросы на Лента.ру ограничены временем, и соответственно, точное ограничение найти не получится. Более того, на Лента.ру сразу выдается текст статьи в json таблице, с РБК приходится дополнительно парсить текст со страниц.  "
      ],
      "metadata": {
        "id": "wYPaUXgJjRpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Парсер для РБК\n",
        "\n"
      ],
      "metadata": {
        "id": "1Ovbv0O_jRpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class rbc_parser:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def _get_url(self, param_dict: dict) -> str:\n",
        "        \"\"\"\n",
        "        Возвращает URL для запроса json таблицы со статьями\n",
        "        \"\"\"\n",
        "        url = 'https://www.rbc.ru/v10/search/ajax/?\\\n",
        "        project={0}&\\\n",
        "        category={1}&\\\n",
        "        dateFrom={2}&\\\n",
        "        dateTo={3}&\\\n",
        "        offset={4}&\\\n",
        "        limit={5}&\\\n",
        "        query={6}&\\\n",
        "        material={7}'.format(param_dict['project'],\n",
        "                            param_dict['category'],\n",
        "                            param_dict['dateFrom'],\n",
        "                            param_dict['dateTo'],\n",
        "                            param_dict['offset'],\n",
        "                            param_dict['limit'],\n",
        "                            param_dict['query'],\n",
        "                            param_dict['material'])\n",
        "        \n",
        "        return url\n",
        "    \n",
        "    \n",
        "    def _get_search_table(self, param_dict: dict,\n",
        "                          includeText: bool = True) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Возвращает pd.DataFrame со списком статей\n",
        "        \n",
        "        includeText: bool\n",
        "        ### Если True, статьи возвращаются с текстами\n",
        "        \"\"\"\n",
        "        url = self._get_url(param_dict)\n",
        "        r = rq.get(url)\n",
        "        search_table = pd.DataFrame(r.json()['items'])\n",
        "        if includeText and not search_table.empty:\n",
        "            get_text = lambda x: self._get_article_data(x['fronturl'])\n",
        "            search_table[['overview', 'text']] = search_table.apply(get_text,\n",
        "                                                                    axis=1).tolist()\n",
        "            \n",
        "        return search_table.sort_values('publish_date_t', ignore_index=True)\n",
        "    \n",
        "    \n",
        "    def _get_article_data(self, url: str):\n",
        "        \"\"\"\n",
        "        Возвращает описание и текст статьи по ссылке\n",
        "        \"\"\"\n",
        "        r = rq.get(url)\n",
        "        soup = bs(r.text, features=\"lxml\") # features=\"lxml\" чтобы не было warning\n",
        "        div_overview = soup.find('div', {'class': 'article__text__overview'})\n",
        "        if div_overview:\n",
        "            overview = div_overview.text.replace('<br />','\\n').strip()\n",
        "        else:\n",
        "            overview = None\n",
        "        p_text = soup.find_all('p')\n",
        "        if p_text:\n",
        "            text = ' '.join(map(lambda x:\n",
        "                                x.text.replace('<br />','\\n').strip(),\n",
        "                                p_text))\n",
        "        else:\n",
        "            text = None\n",
        "        \n",
        "        return overview, text \n",
        "    \n",
        "    def get_articles(self,\n",
        "                     param_dict,\n",
        "                     time_step = 7,\n",
        "                     save_every = 5,\n",
        "                     save_excel = True) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Функция для скачивания статей интервалами через каждые time_step дней\n",
        "        Делает сохранение таблицы через каждые save_every * time_step дней\n",
        "\n",
        "        param_dict: dict\n",
        "        ### Параметры запроса \n",
        "        ###### project - раздел поиска, например, rbcnews\n",
        "        ###### category - категория поиска, например, TopRbcRu_economics\n",
        "        ###### dateFrom - с даты\n",
        "        ###### dateTo - по дату\n",
        "        ###### offset - смещение поисковой выдачи\n",
        "        ###### limit - лимит статей, максимум 100\n",
        "        ###### query - поисковой запрос (ключевое слово), например, РБК\n",
        "\n",
        "        \"\"\"\n",
        "        param_copy = param_dict.copy()\n",
        "        time_step = timedelta(days=time_step)\n",
        "        dateFrom = datetime.strptime(param_copy['dateFrom'], '%d.%m.%Y')\n",
        "        dateTo = datetime.strptime(param_copy['dateTo'], '%d.%m.%Y')\n",
        "        if dateFrom > dateTo:\n",
        "            raise ValueError('dateFrom should be less than dateTo')\n",
        "        \n",
        "        out = pd.DataFrame()\n",
        "        save_counter = 0\n",
        "\n",
        "        while dateFrom <= dateTo:\n",
        "            param_copy['dateTo'] = (dateFrom + time_step).strftime(\"%d.%m.%Y\")\n",
        "            if dateFrom + time_step > dateTo:\n",
        "                param_copy['dateTo'] = dateTo.strftime(\"%d.%m.%Y\")\n",
        "            print('Parsing articles from ' + param_copy['dateFrom'] +  ' to ' + param_copy['dateTo'])\n",
        "            out = out.append(self._get_search_table(param_copy), ignore_index=True)\n",
        "            dateFrom += time_step + timedelta(days=1)\n",
        "            param_copy['dateFrom'] = dateFrom.strftime(\"%d.%m.%Y\")\n",
        "            save_counter += 1\n",
        "            if save_counter == save_every:\n",
        "                display.clear_output(wait=True)\n",
        "                out.to_excel(\"/tmp/checkpoint_table.xlsx\")\n",
        "                print('Checkpoint saved!')\n",
        "                save_counter = 0\n",
        "        \n",
        "        if save_excel:\n",
        "            out.to_excel(\"rbc_{}_{}.xlsx\".format(\n",
        "                param_dict['dateFrom'],\n",
        "                param_dict['dateTo']))\n",
        "        print('Finish')\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "1xwhXhO0jLNJ",
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Парсер для Лента.ру"
      ],
      "metadata": {
        "id": "EZhoIPn4jRpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class lentaRu_parser:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def _get_url(self, param_dict: dict) -> str:\n",
        "        \"\"\"\n",
        "        Возвращает URL для запроса json таблицы со статьями\n",
        "\n",
        "        url = 'https://lenta.ru/search/v2/process?'\\\n",
        "        + 'from=0&'\\                       # Смещение\n",
        "        + 'size=1000&'\\                    # Кол-во статей\n",
        "        + 'sort=2&'\\                       # Сортировка по дате (2), по релевантности (1)\n",
        "        + 'title_only=0&'\\                 # Точная фраза в заголовке\n",
        "        + 'domain=1&'\\                     # ??\n",
        "        + 'modified%2Cformat=yyyy-MM-dd&'\\ # Формат даты\n",
        "        + 'type=1&'\\                       # Материалы. Все материалы (0). Новость (1)\n",
        "        + 'bloc=4&'\\                       # Рубрика. Экономика (4). Все рубрики (0)\n",
        "        + 'modified%2Cfrom=2020-01-01&'\\\n",
        "        + 'modified%2Cto=2020-11-01&'\\\n",
        "        + 'query='                         # Поисковой запрос\n",
        "        \"\"\"\n",
        "        hasType = int(param_dict['type']) != 0\n",
        "        hasBloc = int(param_dict['bloc']) != 0\n",
        "\n",
        "        url = 'https://lenta.ru/search/v2/process?'\\\n",
        "        + 'from={}&'.format(param_dict['from'])\\\n",
        "        + 'size={}&'.format(param_dict['size'])\\\n",
        "        + 'sort={}&'.format(param_dict['sort'])\\\n",
        "        + 'title_only={}&'.format(param_dict['title_only'])\\\n",
        "        + 'domain={}&'.format(param_dict['domain'])\\\n",
        "        + 'modified%2Cformat=yyyy-MM-dd&'\\\n",
        "        + 'type={}&'.format(param_dict['type']) * hasType\\\n",
        "        + 'bloc={}&'.format(param_dict['bloc']) * hasBloc\\\n",
        "        + 'modified%2Cfrom={}&'.format(param_dict['dateFrom'])\\\n",
        "        + 'modified%2Cto={}&'.format(param_dict['dateTo'])\\\n",
        "        + 'query={}'.format(param_dict['query'])\n",
        "        \n",
        "        return url\n",
        "\n",
        "\n",
        "    def _get_search_table(self, param_dict: dict) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Возвращает pd.DataFrame со списком статей\n",
        "        \"\"\"\n",
        "        url = self._get_url(param_dict)\n",
        "        r = rq.get(url)\n",
        "        search_table = pd.DataFrame(r.json()['matches'])\n",
        "        \n",
        "        return search_table\n",
        "\n",
        "    \n",
        "    def get_articles(self,\n",
        "                     param_dict,\n",
        "                     time_step = 37,\n",
        "                     save_every = 5, \n",
        "                     save_excel = True) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Функция для скачивания статей интервалами через каждые time_step дней\n",
        "        Делает сохранение таблицы через каждые save_every * time_step дней\n",
        "\n",
        "        param_dict: dict\n",
        "        ### Параметры запроса \n",
        "        ###### project - раздел поиска, например, rbcnews\n",
        "        ###### category - категория поиска, например, TopRbcRu_economics\n",
        "        ###### dateFrom - с даты\n",
        "        ###### dateTo - по дату\n",
        "        ###### offset - смещение поисковой выдачи\n",
        "        ###### limit - лимит статей, максимум 100\n",
        "        ###### query - поисковой запрос (ключевое слово), например, РБК\n",
        "\n",
        "        \"\"\"\n",
        "        param_copy = param_dict.copy()\n",
        "        time_step = timedelta(days=time_step)\n",
        "        dateFrom = datetime.strptime(param_copy['dateFrom'], '%Y-%m-%d')\n",
        "        dateTo = datetime.strptime(param_copy['dateTo'], '%Y-%m-%d')\n",
        "        if dateFrom > dateTo:\n",
        "            raise ValueError('dateFrom should be less than dateTo')\n",
        "        \n",
        "        out = pd.DataFrame()\n",
        "        save_counter = 0\n",
        "\n",
        "        while dateFrom <= dateTo:\n",
        "            param_copy['dateTo'] = (dateFrom + time_step).strftime('%Y-%m-%d')\n",
        "            if dateFrom + time_step > dateTo:\n",
        "                param_copy['dateTo'] = dateTo.strftime('%Y-%m-%d')\n",
        "            print('Parsing articles from '\\\n",
        "                  + param_copy['dateFrom'] +  ' to ' + param_copy['dateTo'])\n",
        "            out = out.append(self._get_search_table(param_copy), ignore_index=True)\n",
        "            dateFrom += time_step + timedelta(days=1)\n",
        "            param_copy['dateFrom'] = dateFrom.strftime('%Y-%m-%d')\n",
        "            save_counter += 1\n",
        "            if save_counter == save_every:\n",
        "                display.clear_output(wait=True)\n",
        "                out.to_excel(\"/tmp/checkpoint_table.xlsx\")\n",
        "                print('Checkpoint saved!')\n",
        "                save_counter = 0\n",
        "            \n",
        "        if save_excel:\n",
        "            out.to_excel(\"lenta_{}_{}.xlsx\".format(\n",
        "                param_dict['dateFrom'],\n",
        "                param_dict['dateTo']))\n",
        "        print('Finish')\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "xYqhPr1yRjQY",
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пример выгрузки данных"
      ],
      "metadata": {
        "id": "ViAqGOksjRpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### РБК\n",
        "\n",
        "* __project__ - проекты РБК. Возможные значения: [\"rbcnews\", \"rbctv\", \"rbcstyle\", \"sport\", \"realty\", \"crypto\", \"autonews\", \"quote\", \"bc3\", \"trends\"]\n",
        " \n",
        "* __category__ - рубрики: [\"TopRbcRu_economics\", \"TopRbcRu_auto\", \"TopRbcRu_business\", \"TopRbcRu_money\", \"TopRbcRu_realty\", \"TopRbcRu_society\", \"TopRbcRu_politics\", \"TopRbcRu_own_business\", \"TopRbcRu_specials\", \"TopRbcRu_technology_and_media\", \"TopRbcRu_finances\"]\n",
        "\n",
        "* __material__ - материалы: [\"video\", \"quiz\", \"interview\", \"research\", \"card\", \"opinion\", \"multimedia\", \"short_news\", \"olympics_online\", \"online\", \"investigation\", \"rating\", \"article_specproject\", \"article\", \"story\"]\n",
        "\n",
        "* __dateFrom__ - с даты \n",
        "\n",
        "* __dateTo__ - по дату \n",
        "\n",
        "* __offset__ - смещение поисковой выдачи (от 0 до 100)\n",
        "\n",
        "* __limit__ - лимит запроса, максимум 100 \n",
        "\n",
        "_Чтобы не специфировать параметр, оставляем поле пустым_"
      ],
      "metadata": {
        "id": "MljsEAO7jRpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем параметры запросы и складываем в param_dict\n",
        "use_parser = \"РБК\"\n",
        "\n",
        "query = 'РБК'\n",
        "project = \"rbcnews\"\n",
        "category = \"TopRbcRu_economics\"\n",
        "material = \"\"\n",
        "dateFrom = '2021-01-01'\n",
        "dateTo = \"2021-02-28\"\n",
        "offset = 0\n",
        "limit = 100\n",
        "\n",
        "if use_parser == \"РБК\":\n",
        "    param_dict = {'query'   : query, \n",
        "                  'project' : project,\n",
        "                  'category': category,\n",
        "                  'dateFrom': datetime.\n",
        "                  strptime(dateFrom, '%Y-%m-%d').\n",
        "                  strftime('%d.%m.%Y'),\n",
        "                  'dateTo'  : datetime.\n",
        "                  strptime(dateTo, '%Y-%m-%d').\n",
        "                  strftime('%d.%m.%Y'),\n",
        "                  'offset'  : str(offset),\n",
        "                  'limit'   : str(limit),\n",
        "                  'material': material}\n",
        "\n",
        "print(use_parser, \"- param_dict:\", param_dict)"
      ],
      "metadata": {
        "id": "3thQqZuQOMd9",
        "outputId": "a30bdf80-b9dd-4c8e-9691-69ae0765ba0c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "РБК - param_dict: {'query': 'РБК', 'project': 'rbcnews', 'category': 'TopRbcRu_economics', 'dateFrom': '01.01.2021', 'dateTo': '28.02.2021', 'offset': '0', 'limit': '100', 'material': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример того, как выглядит json таблица запроса по параметрам.\n",
        "# Действует ограничение в 100 статей на 1 запрос (параметром limit)\n",
        "assert use_parser == \"РБК\"\n",
        "parser = rbc_parser()\n",
        "tbl = parser._get_search_table(param_dict,\n",
        "                               includeText = True) # Парсить текст статей\n",
        "print(len(tbl))\n",
        "tbl.head()"
      ],
      "metadata": {
        "id": "isXrJKyHYZzM",
        "outputId": "b6923a36-ddfe-4531-fbb7-5343c432ac16",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f8f08985a10>: Failed to establish a new connection: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='perm.rbc.ru', port=443): Max retries exceeded with url: /perm/freenews/628f44349a7947a4832536fa (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f8f08985a10>: Failed to establish a new connection: [Errno 110] Connection timed out'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-163f10a76c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbc_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m tbl = parser._get_search_table(param_dict,\n\u001b[0;32m----> 6\u001b[0;31m                                includeText = True) # Парсить текст статей\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0a54e1eb9e1b>\u001b[0m in \u001b[0;36m_get_search_table\u001b[0;34m(self, param_dict, includeText)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mget_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_article_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fronturl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             search_table[['overview', 'text']] = search_table.apply(get_text,\n\u001b[0;32m---> 36\u001b[0;31m                                                                     axis=1).tolist()\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msearch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'publish_date_t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0a54e1eb9e1b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msearch_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mincludeText\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msearch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mget_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_article_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fronturl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             search_table[['overview', 'text']] = search_table.apply(get_text,\n\u001b[1;32m     36\u001b[0m                                                                     axis=1).tolist()\n",
            "\u001b[0;32m<ipython-input-3-0a54e1eb9e1b>\u001b[0m in \u001b[0;36m_get_article_data\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mВозвращает\u001b[0m \u001b[0mописание\u001b[0m \u001b[0mи\u001b[0m \u001b[0mтекст\u001b[0m \u001b[0mстатьи\u001b[0m \u001b[0mпо\u001b[0m \u001b[0mссылке\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# features=\"lxml\" чтобы не было warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdiv_overview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'article__text__overview'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='perm.rbc.ru', port=443): Max retries exceeded with url: /perm/freenews/628f44349a7947a4832536fa (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f8f08985a10>: Failed to establish a new connection: [Errno 110] Connection timed out'))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример работы программы итеративного сбора большого количества текстов статей\n",
        "# Работает, конечно, очень долго :(\n",
        "table = parser.get_articles(param_dict=param_dict,\n",
        "                             time_step = 7, # Шаг - 7 дней, можно больше,\n",
        "                                            # но есть риск отсечения статей в неделях, гдестатей больше 100\n",
        "                             save_every = 5, # Сохранять чекпойнт каждые 5 шагов\n",
        "                             save_excel = True) # Сохранить итоговый файл\n",
        "print(len(table))\n",
        "table.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "fi3vLtFyjRpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лента.ру\n",
        "\n",
        "* __query__ - поисковой запрос (ключевое слово)\n",
        "\n",
        "* __offset__ - cмещение поисковой выдачи (от 0 до __size__)\n",
        "\n",
        "* __size__ - количество статей. Ограничено время запроса, точного лимита нет. 1000 работает почти всегда \n",
        "\n",
        "* __sort__ - сортировка по дате: (2) - по убыванию, (3) - по возрастанию; по релевантности (1) \n",
        "\n",
        "* __title_only__ - точная фраза в заголовке (1)\n",
        "\n",
        "* __domain__ - ? \n",
        "\n",
        "* __material__ - материалы: Все материалы (0). Новость (1). [\"0\", \"1\", \"2\", \"3\", \"4\", ...]\n",
        "\n",
        "* __block__ - рубрика: Экономика (4). Все рубрики (0). [\"0\", \"1\", \"2\", \"3\", \"4\", ...]\n",
        "\n",
        "* __dateFrom__ - с даты\n",
        "\n",
        "* __dateTo__ - по дату\n",
        "\n",
        "_Чтобы не специфировать параметр, оставляем поле пустым_"
      ],
      "metadata": {
        "id": "0C3BxG8ejRpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем тут параметры\n",
        "use_parser = \"LentaRu\"\n",
        "\n",
        "query = ''\n",
        "offset = 0\n",
        "size = 1000\n",
        "sort = \"3\"\n",
        "title_only = \"0\"\n",
        "domain = \"1\"\n",
        "material = \"0\"\n",
        "bloc = \"4\"\n",
        "dateFrom = '2020-01-01'\n",
        "dateTo = \"2020-03-31\"\n",
        "\n",
        "if use_parser == \"LentaRu\":\n",
        "    param_dict = {'query'     : query, \n",
        "                  'from'      : str(offset),\n",
        "                  'size'      : str(size),\n",
        "                  'dateFrom'  : dateFrom,\n",
        "                  'dateTo'    : dateTo,\n",
        "                  'sort'      : sort,\n",
        "                  'title_only': title_only,\n",
        "                  'type'      : material, \n",
        "                  'bloc'      : bloc,\n",
        "                  'domain'    : domain}\n",
        "\n",
        "print(use_parser, \"- param_dict:\", param_dict)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iciOZSTjjRpa",
        "outputId": "27518f03-3f7d-4dfd-da1f-cca4aedebcc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LentaRu - param_dict: {'query': '', 'from': '0', 'size': '1000', 'dateFrom': '2020-01-01', 'dateTo': '2020-03-31', 'sort': '3', 'title_only': '0', 'type': '0', 'bloc': '4', 'domain': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тоже будем собирать итеративно, правда можно ставить time_step побольше, т.к.\n",
        "# больше лимит на запрос статей. И Работает быстрее :)\n",
        "assert use_parser == \"LentaRu\"\n",
        "parser = lentaRu_parser()\n",
        "parser._get_url(param_dict=param_dict)\n",
        "# tbl = parser.get_articles(param_dict=param_dict,\n",
        "#                          time_step = 37,\n",
        "#                          save_every = 5, \n",
        "#                          save_excel = True)\n",
        "\n",
        "# print(len(tbl.index))\n",
        "# tbl.head()"
      ],
      "metadata": {
        "id": "_P68Sk0BpsOa",
        "outputId": "284c4ea3-23c2-402d-8ab6-22de0939efc8",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://lenta.ru/search/v2/process?from=0&size=1000&sort=3&title_only=0&domain=1&modified%2Cformat=yyyy-MM-dd&bloc=4&modified%2Cfrom=2020-01-01&modified%2Cto=2020-03-31&query='"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}